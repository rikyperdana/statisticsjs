# 5. It's All About That Bell

Dalam ilmu statistik simbol lonceng hampir selalu diidentikkan dengan kurva sebaran data yang relatif normal atau ideal. Lalu mengapa sering diwakilkan dengan simbol lonceng? Jawaban sederhananya adalah karena kebetulan mirip sementara jawaban kompleksnya adalah seperti yang dijelaskan oleh matematikawan Jerman bernama Carl Gauss. Gauss meyakini bahwa kurva lonceng adalah bentuk yang paling mewakili distribusi normal, dimana kurva lonceng memiliki ciri khas:

1. nilai dominan cenderung terletak di tengah kurva
2. semakin ke pangkal atau ke ujung kurva data semakin jarang
3. ada kencederungan bentuk simetris pada sisi kiri dan kanan kurva

Banyak juga statistikawan yang percaya bahwa kurva bel adalah bentuk yang paling alamiah untuk mencul di alam semesta, dan memang sering terjadi (bukan selalu). Contoh yang paling sederhana adalah distribusi nilai berat badan pada sebuah kelas. Kita akan lebih umum menemukan kelas yang mayoritas mahasiswanya memiliki berat badan 50-60kg sementara sisanya berbobot 40-50kg dan 60-70kg dan dapat dihitung dengan cari mahasiswa anoreksia (<40kg) atau yang obesitas (>90kg). Tanpa perlu menggambarkan kurvanya pun kita juga sudah bisa membayangkan bahwa berat badan semua mahasiswa di kelas tersebut akan berdistribusi normal. Tapi di Jepang ada juga kelas yang rata-rata bobot anggotanya di 120-150kg, namanya kelas atlit Sumo. Distribusi data mereka bisa jadi normal, tapi kan sudah beda populasi dengan kelas yang sebelumnya. Dari distribusi data berat badan hingga distribusi materi di alam semesta, semuanya memiliki kemungkinan/kecenderungan untuk menyerupai atau mendekati bentuk bel.

Mudah bagi manusia untuk men-judge apakah suatu kurva sudah mendekati distribusi normal atau belum dilihat dari sudah seberapa mirip ia dengan bentuk bel. Tapi justifikasi manusia adalah hal yang sangat subjektif dan bertentangan dengan prinsip objektifitas statistik. Untungnya ilmu statistik menyediakan beberapa kotak perkakas yang berisi alat-alat ukur untuk membantu ahli statistik mengamati kurva dengan cara yang lebih objektif dan matematis. Ketiga kota perkakas yang akan kita bahas dalam buku ini adalah: 1. Dispersion, 2. Skewness, 3. Kurtosis

## 5.1. Dispersion
Dispersion adalah suatu ukuran seberapa jauh setiap nilai dalam data terhadap nilai pertengahan data tersebut. Karena dispersi adalah soal membandingkan data maka pembaca wajib untuk lebih dahulu memahami yang lebih basic seperti central tendency, kuartil, dan bahasan lain pada bab-bab sebelumnya. Dispersion yang telah kita analogikan sebagai kotak perkakas terdiri dari alat-alat sebagai berikut:

### 5.1.1. Range
Pada bab-bab sebelumnya kita telah lebih dulu akrab dengan konsep range untuk ekbutuhan berbagai formula namun disini dibahas kembali sebagai pengingat. Berikut ini adalah kode-kode JS untuk menemukan range baik untuk data tunggal maupun yang distribusi frekuensi berkelompok:

```
range = array => Math.max(...array) - Math.min(...array),
distRange = dist =>
  (dist[dist.length - 1].top + 0.5) -
  (dist[0].bot - 0.5)

range(data) // hasilnya 17
distRange(distFreq(data)) // hasilnya 18
```

Perlu diperhatikan disini bahwa nilai jangkauan (range) distribusi frekuensi akan selalu lebih besar dari range data tunggalnya karena yang menjadi acuannya adalah batas bawah dan batas atas data berkelompok. Lalu manfaat apa yang bisa kita peroleh dari mengetahui hasil range? Pertama adalah kita mengetahui rentang data dari yang terkecil hingga ke yang terbesar, kita tahu bahwa selisih maksimal antar data tidak mungkin lebih besar dari range. Kedua ada banyak formula lainnya yang memanfaatkan range sebagai bahan perhitungan.

### 5.1.2. Intequartile Range
Sesuai namanya, IQR adalah jarak dari data kuartil pertama dan ketiga (terakhir). Maka rumus matematisnya pun sederhana pula yaitu IQR = Q3 - Q1 yang jika dikonversi menjadi kode JS:

```
iQR = array => fractile(4, 3, array) - fractile(4, 1, array),

distIQR = dist =>
  distFractile(4, 3, distCumulative(dist)) -
  distFractile(4, 1, distCumulative(dist))

iQR(data) // hasilnya 4
distIQR(distFreq(data)) // hasilnya 4,68
```

Apa manfaat yang bisa diperolehd ari mengetahui informasi jarak antar kuartil? Yaitu untuk mengetahui data pencilan atau outlier, nilai yang kemunculannya relatif jauh dari nilai rata-rata hitung. Memang kenapa kalau ada data outlier? Sebenarnya kemunculan data outlier adalah hal yang natural di lapangan, hanya saja kehadiran outlier tersebut dapat merusak bentuk bel yang umumnya memvisualisasikan normalitas distribusi. Di lain sisi, keberadaan data outlier juga mengindikasikan bahwa data outlier tersebut mungkin lebih tepat bila ditempatkan pada populasi lain dimana ia bisa dianggap normal. Distribusi tidak normal pada sebuah kelompok data tidak mengartikan bahwa data yang dikumpulkan tersebut jelek melainkan untuk menunjukkan bahwa tidak semua konstituen dalam data dapat terwakili dengan baik oleh hasil olah data statistiknya. Bila keterangan diatas masih cukup abstrak dan teknikal, mari penulis coba perkuat pemahamannya dengan sebuah contoh kasus.

Pada sebuah kelas di SMA unggulan terdapat 20 siswa-siswi didik dimana salah seorang anak diantara mereka adalah outlier. 19 anak diantaranya memiliki prestasi yang cukup bagus dilihat dari pencapaian nilai berbagai mata pelajaran, kelas seni dan kelas olah raga. 1 orang anak outlier tersebut memiliki nilai yang sangat rendah di bidang kesenian dan olah raga namun memiliki nilai sempurna pada mata pelajaran eksakta. Bila mata pelajaran seni dan olah raga digambarkan dalam kurva, maka Anda bisa membayangkan bahwa naka tersebut akan berada di ujung kiri distribusi dan berada di ujungkanan kurva distribusi nilai mata pelajaran eksakta. Dalam perspektif statistik, meski datanya benar apa adanya tapi tergolong tidak berdistribusi normal. Kehadiran anak outlier tersebut merusak central tendency, fraktil, dan alat ukur lainnya. Jelas bahwa selagi anak outlier tersebut masih berada di kelas tersebut maka statistik tidak bisa memberikan representasi yang akurat mewakili 19 anak dan 1 anak outlier tersebut sekaligus. Mungkin lebih tepat bila 1 anak outlier tersebut ditempatkan pada kelas lain yang anak-anaknya memiliki kecenderungan serupa dengan dia, dimana dalam kelas baru tersebut ia dapat terdistribusi normal.

Analogi diatas dapat pula berlaku pada bidang ilmu lainnya yang memanfaatkan statistik untuk penalaran data seperti fisika, kimia, biologi, hingga ilmu sosial. Semoga dengan ini Anda lebih memahami apa makna, karakteristik, dan kegunaan dari pengetahui distribusi normal.

### 5.1.3. Deviasi Rata-rata
Alat berikutnya dalam kotak perkakas dispersi adalah deviasi rata-rata. Deviasi sendiri adalah selisih absolut setiap nilai terhadap rata-rata hitungnya dan deviasi rata-rata adalah rata-rata dari keseluruhan deviasi tersebut. Berikut ini adalah rumus matematis dari deviasi rata-rata:

DR = (1/n) * Sigma|X - Xbar|

Jika dikonversikan menjadi kode JS maka bentuknya seperti ini:

```
devMean = array => withThis(
  mean(array), meanVal => add(
    array.map(i => i - meanVal)
         .map(Math.abs)
  ) / array.length
),

distDevMean = dist => withThis(
  distMean(dist), meanVal => add(
    dist.map(i => i.fre * Math.abs(
      (i.bot + ((i.top - i.bot) / 2)) - meanVal
    ))
  ) / add(dist.map(get('fre')))
)

devMean(data) // hasilnya 2,77875
distDevMean(distFreq(data)) // hasilnya 2,98125
```

Lalu apa gunanya kita mengetahui nilai rata-rata deviasi? Angka yang dihasilkan oleh formula diatas menggambarkan seberapa jauh jarak rata-rata setiap data terhadap nilai tengahnya. Semakin besar angka tersebut maka diduga akan semakin melebar pula kurvanya baik ke kiri atau ke kanan, semakin kecil angka tersebut maka akan semakin mengerucut ketengah kurva belnya. Dan kurva mana yang dapat dianggap lebih bagus? Tidak masalah apakah nilai dari devMean-nya besar atau kecil selagi bentuknya tetap simetris, minim data outlier, dan tidak terlalu miring ke salah satu sisi.

### 5.1.4. Varians
Bila pada devMean yang dihitung adalah rata-rata absolut nilai selisih maka pada varians yang dihitung adalah rata-rata kuadrat nilai selisih. Formula matematisnya adalah sebagai berikut:

s^2 = (1/n) * Sigma(X - Xbar)^2

Catatan: ganti n dengan (n - 1) bila sampel yang dihitung jumlahnya tidak sampai 30

Jika dikonversi menjadi kode JS maka bentuknya adalah sebagai berikut:

```
variance = array => withThis(
  mean(array), meanVal => add(
    array.map(i => i - meanVal)
         .map(pow(2))
  ) / (array.length - (
    array.length > 30 ? 0 : 1
  ))
)

distLength = dist => add(dist.map(get('fre'))),

distVariance = dist => withThis(
  distMean(dist), meanVal => add(
    dist.map(i => i.fre * pow(2)(
      (i.bot + ((i.top - i.bot) / 2)) - meanVal
    ))
  ) / distLength(dist) - (
    distLength(dist) > 30 ? 0 : 1
  )
)

variance(data) // hasilnya 13,0693
distVariance(distFreq(data)) // hasilnya 13,3593
```

Lalu apa manfaatnya dengan mengetahui nilai varians sebuah himpunan data? Kurang lebih penjelasannya sama dengan pada sub-bab rata-rata deviasi sebelumnya.

### 5.1.5. Standar Deviasi
Sederhananya adalah akar kuadrat dari hasil perhitungan varians, yang rumus matematisnya adalah:

sD = v^1/2

Dan kode JS-nya juga sederhana yaitu:

```
stanDev = pow(1/2)

stanDev(variance(data)) // hasilnya 3,6151
stanDev(distVariance(distFreq(data))) // hasilnya 3,6550
```

### 5.1.6. Relative Dispersion
Semua alat hitung dispersi diatas tergolong dispersi absolut, yang artinya membandingkan perbedaan setiap data dengan rata-ratanya sendiri. Untuk dapat membandingkan dispersi pada 2 atau lebih set data yang berbeda maka kita membutuhkan dispersi relatif. Cara mengerjakannya cukup mudah bahkan kita tiak membutuhkan formula yang kompleks. Berikut ini adalah beberapa ukuran dispersi relatif:
1. koefisien variasi = standarDeviasi / Xbar * 100%
2. variasi jangkauan = range / Xbar * 100%
3. variasi kuartil = Qd / Median * 100%
4. variasi simpangan rata-rata = SR / Xbar * 100%

Dari sini kita dapat melihat bahwa seluruh formula variasi memiliki bentuk yang sederhana dan pola yang sama, yaitu membagi pembilang dan penyebut lalu mengalikannya dengan 100 agar menjadi persentase. Maka ktia bisa membangun kode JS yang generik untuk semua jenis variasi:

```
variation = (a, b) => a / b * 100

// Cara penggunaan

variation(
  stanDev(variance(data)), mean(data)
) // result 4.9471899
variation(
  stanDev(distVariance(distFreq(data))),
  distMean(distFreq(data))
) // result 4.9983
variation(range(data), mean(data)) // result 23.263
variation(
  distRange(distFreq(data)),
  distMean(distFreq(data))
) // result 24.61538
variation(iQR(data), median(data)) // result 5.4794
variation(
  distIQR(distFreq(data)),
  distMedian(distFreq(data))
) // result 6.58965


```
### 5.1.7. Kemiringan
Bahkan tidak semua kurva bel itu berbentuk simetris yang sempurna. Pada beberapa kasus, Anda akan menemukan bahwa 
ada kurva yang miring ke salah satu sisi. Anda dapat mengidentifikasi kemiringan ini dari melihat kakinya yang 
lebih panjang sebelah atau puncak gunungnya yang lebih condong ke salah satu sisi. Maka, dalam statistik fenomena 
ini populer disebut dengan skewness atau yang dalam bahasa Indonesianya disebut kemencengan/kemiringan.

Mata manusia bisa saja dengan mudah mendeteksi kemiringan kurva bel bila kemiringannya memang kentara. Tapi mata 
kita tidak mungkin cukup sensitif untuk mendeteksi kemiringan yang sangat tipis. Untuk itu kita bisa mengandalkan 
statistik untuk mengukur kemiringan tersebut. Ukuran sempurnanya kurva adalah ketika Xbar = Median = Moda. Bila 
salah satu saja dari mereka ada yang nilainya tidak sama maka aman untuk kita berasumsi bahwa kurva tersebut 
memiliki gejala kemiringan. Tapi seberapa miring dan ke arah mana miringnya?

Arah kemiringan kurva dapat kita tentukan dari puncak sebelah mana yang lebih tinggi. Bila tingginya di sebelah 
kiri maka disebut menceng ke kiri atau negatif, sementara bila puncaknya condong ke kanan maka disebut menceng 
positif. Sekarang mari kita tanggalkan subjektifitas kita dan gunakan statistik agar lebih objektif dalam 
menentukan kemiringan kurva.

#### 5.1.7.1. Kemencengan Pearson
Pearson berpendapat bahwa koefisien kemiringan dapat diukur dengan cara membandingkan antara mean dan moda lalu 
membaginya dengan standar deviasi. Bila dijabarkan dalam formula maka bentuknya adalah seperti ini:

Sk1 = (Xbar - Moda) / s

Tapi sayangnya tidak semua distribusi memiliki moda, untuk itu Pearson menyediakan formula alternatif yang tidak 
mengandalkan moda, tapi median. Rumusnya adalah sebagai berikut:

Sk2 = 3(Xbar - Med) / s

[ambil contoh kode di gist rikyperdana]

Dari hasil olah data diatas didapati bahwa data yang kita gunakan dalam buku ini memiliki kecenderungan untuk 
menceng ke arah kiri/negatif menurut perhitungan yang berdasarkan moda. Tetapi ketika dihitung dengan formula 
berbasi median maka kurva dianggap positif. Perbedaan hasil hitung formula yang berbasi moda dan median adalah hal 
yang normal, karena titik acuang yang berbeda. Justru perbedaan ini mengindikasikan bahwa kurva relatif simetris 
kiri dan kanan. Sementara bila Anda menemukan bahwa kedua formula menghasilkan nilai negatif maka Anda lebih yakin 
bahwa kurvanya memang menceng ke arah negatif, begitu pula bila kasusnya keduanya bernilai positif.

#### 5.1.7.2. Kemiringan Bowley
Bukan hanya Pearson yang memikirkan tentang kemiringan kurva, tapi juga seorang Sir Arthur Lyon Bowley. Bowley 
mencoba menghitung kemencengan bukan dengan moda ataupun median seperti yang dilakukan Pearson, tapi dengan selisih 
antar kuartil-kuartil. Rumusnya adalah sebagai berikut:

SkB = ((Q3 - Q2) - (Q2 - Q1)) / ((Q3 - Q2) - (Q2 - Q1))

Yang jika dikonversi menjadi kode JS maka bentuknya seperti ini:

[ambil kode JS dari gist rikyperdana]

Dari hasil uji kode diatas dapat kita lihat bahwa dengan menggunakan himpunan data tunggal nilai skewness adalah 0, 
sementar dari data distribusi frekuensi didapati nilai minus yang relatif kecil. Perbedaan ini adalah hal yang 
wajar, karena data distribusi frekuensi adalah data tunggal yang disimplifikasi.

#### 5.1.7.3. Kemiringan Persentil
Bila Bowley mengukur kemiringan berdasarkan kuartil, maka kemiringan juga bisa diukur dengan persentil, formulanya 
adalah:

SkP = ((P90 - P50) - (P50 - P10)) / (P50 - P10)

Yang jika dikonversi dalam bentuk kode JS maka bentuknya adalah:

[ambil kode JS dari gist rikyperdana]

#### 5.1.7.4. Kemiringan Moment
Kemiringan juga dapat dihitung dengan menggunakan perbandingan mement ke-3 dan pangkat 3 simpangan baku. Ada 
hubungan yang unik antara mean, varians, kemiringan, dan keruncingan, semuanya terletak pada level perpangkatan 
yang digunakan, seperti yang ditunjukkan pada gambar di bawah:

[ambil gambar hubungan perpangkatan kemiringan moment dari Google Images]

Bila ingin menghitung kemiringan Moment pada data tunggal, maka gunakan rumus berikut:

SkewMoment = Sigma(X - Xbar)/n*s^3

Yang bila dikonversi menjadi kode JS maka bentuknya adalah:

[ambil fungsi skewMom dari gist rikyperdana]

Bila ingin menghitung kemiringan Moment pada data distribusi, maka gunakan rumus berikut:

SkewMoment = Sigma(X - Xbar)f/n*s^3
